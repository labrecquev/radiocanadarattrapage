import requests
from bs4 import BeautifulSoup
import dateparser
import os
from datetime import datetime, timedelta
import re
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
import ast


def lambda_handler(event, context):
    now = datetime.now()

    def main():
        global radio_shows_dict, rattrapage_data, email_summary
        start = datetime.now()
        print(f"Script start, retrieving {now.date()}'s shows. It is {datetime.now()}")
        
        # get credentials and email info
        pwd = os.getenv('MY_PASSWORD')
        mail_user = os.getenv('MAIL_USER')
        mail_list = os.getenv('MAIL_LIST')
        radio_shows_url = "https://ici.radio-canada.ca/ohdio/premiere/emissions/?regionIds=8"

        # main functions
        radio_shows_dict = get_radio_shows(radio_shows_url)
        rattrapage_data = get_rattrapage_data(radio_shows_dict)
        email_summary = build_email_summary(rattrapage_data)
        send_email_summary(email_summary, mail_user, mail_list, pwd)
        
        duration = datetime.now() - start
        
        print(f"Script done, it took {duration}")
        
    def get_radio_shows(url):
        response = requests.get(url)
        radio_shows_dict = {}
        
        if not response.status_code == 200:
            print(f"\tFailed to retrieve HTML: {response.status_code}")                
        else:
            print("\tHTML read successfully")
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            radio_shows = soup.find('ol', class_='index-grid-list')        
            radio_shows = radio_shows.find_all('li')
            
            for radio_show in radio_shows:
                a_tag = radio_show.find('a')
                if not a_tag:
                    print("no href, next list item")
                    continue
                href = a_tag.get('href')
                show_name = a_tag.find('span').text
                url = "https://ici.radio-canada.ca" + href
                radio_shows_dict[show_name] = url
            return radio_shows_dict
            
    def french_date_parser(string):
        month_name_repl_dict = {'janv.':'janvier',
                        'févr.':'février',
                        'fév.':'février',
                        'avr.':'avril',
                        'juill.':'juillet',
                        'sept.':'septembre',
                        'oct.':'octobre',
                        'nov.':'novembre',
                        'déc.':'décembre'}
        # Define the regex pattern for French dates
        pattern = r'\b([1-9]|[12][0-9]|3[01])\w*\s(janvier|février|mars|avril|mai|juin|juillet|août|septembre|octobre|novembre|décembre|janv.|févr.|avr.|juill.|sept.|oct.|nov.|déc.)\s(\d{4})\b'
        date_pattern = re.compile(pattern, re.IGNORECASE)
        match = date_pattern.search(string)
        raw_date = match.group()
        for month_abbrv, fullmonthname in month_name_repl_dict.items():
            raw_date = raw_date.replace(month_abbrv, fullmonthname)
        parsed_date = dateparser.parse(raw_date)
        if parsed_date:
            return parsed_date
        else:
            print(f"Could not parse date from:\n{string}")
        
    def get_rattrapage_data(radio_shows_dict):
        rattrapage_data = {}
        
        for name, url in radio_shows_dict.items():
            print(f"\n{name}\n{url}")
            
            response = requests.get(url)
            
            if not response.status_code == 200:
                print(f"\tFailed to retrieve HTML: {response.status_code}")
                continue
            
            print("\tHTML read successfully")
            response = response.text                
        
            soup = BeautifulSoup(response, 'html.parser')
            
            emissions = soup.find('ul', class_='list-cue')
            
            if not emissions:
                print("no rattrapage, next show")
                continue
        
            li_items = emissions.find_all('li')
            
            scraped_emissions = {}
            
            for li in li_items:
                h_tag = li.find('h2')
                if not h_tag:
                    print("no header, next list item")
                    continue
                else:
                    a_tag = li.find('a')
                    href = a_tag.get('href')
                    emission_url = f"https://ici.radio-canada.ca{href}"
                if not a_tag:
                    print("no url, next list item")
                    continue
                else:
                    link_text = a_tag.text.strip()
                    try:
                        print(f"Trying to parse date from: {link_text}")
                        parsed_date = french_date_parser(link_text)
                        print(f"{parsed_date}'s show date parsed")
                    except Exception as err:
                        print(f"could not parse date from:\n{link_text}\n{err}")
                        continue
                if not parsed_date:
                    print("no date parsed, next list item")
                    continue
                           
                if not parsed_date.date() == now.date():
                    print("parsed date not today, continue")
                    continue
                    
                text_subtitle = li.find('span', class_='text summary')
                if not text_subtitle:
                    print("no show summary, next list item")
                    continue
                else:
                    print(f"\t\tInserting {parsed_date.date()}'s show into dict")
                    text_subtitle = text_subtitle.text.strip()
                    show_segments = text_subtitle.split(';')
                    rattrapage_data[name] = [emission_url, show_segments, parsed_date.date()]
        return rattrapage_data

    def build_email_summary(rattrapage_data):
        print("\nBuilding email summary")
        # Initialize an empty string to hold the HTML content
        html_content = "<ul>\n"
        
        # Iterate over the dictionary to build the HTML list
        for name, (url, show_segments, date) in rattrapage_data.items():
            html_content += "  <li>\n"
            html_content += f"    <a href='{url}'>{name}, {date}</a>\n"
            html_content += "    <ul>\n"
            for show_segment in show_segments:
                html_content += f"      <li>{show_segment}</li>\n"
            html_content += "    </ul>\n"
            html_content += "  </li>\n"
        
        # Close the unordered list tag
        html_content += "</ul>"
        return html_content
    
    def send_email_summary(email_summary, mail_user, mail_list, pwd):     
        print("\nSending email summary")
        # Email parameters
        sent_from = mail_user
        # sent_to = ', '.join(ast.literal_eval(mail_list))
        sent_to = ast.literal_eval(mail_list)
        subject = f"Rattrapage Radio-Canada du {now.date()}"
        
        # Create the MIME message
        msg = MIMEMultipart('alternative')
        msg['Subject'] = subject
        msg['From'] = sent_from
        msg['To'] = ', '.join(sent_to)        
        
        # Attach the HTML content
        html_part = MIMEText(email_summary, 'html')
        msg.attach(html_part)
        
        # Send the email using SMTP
        try:
            server = smtplib.SMTP_SSL('mail.labrecquev.ca', 465)
            server.ehlo()
            server.login(mail_user, pwd)
            server.sendmail(sent_from, sent_to, msg.as_string())
            server.quit()
            print("Email sent!")
        except Exception as error:
            print(f"Email not sent\n{error=}")

    main()

if __name__ == "__main__":
    from dotenv import load_dotenv
    from pathlib import Path
    env_path = Path(__file__).parent / ".env"
    load_dotenv(dotenv_path=env_path)

    lambda_handler(None,None)